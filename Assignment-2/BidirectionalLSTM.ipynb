{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "working_Q1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6w92lJvYKpTz"
      },
      "source": [
        "# **Note: I am using garbage collector and deleting huge lists to avoid crashing of the notebook due to insufficient RAM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3lCrtvEHb7j"
      },
      "source": [
        "import re\n",
        "import os\n",
        "import gc\n",
        "import math\n",
        "import time\n",
        "import pickle\n",
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPXeIl_zBz6Q"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTAjMV2DvaDk"
      },
      "source": [
        "# **Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vI7fLSAEy9xD"
      },
      "source": [
        "**ROC Curve- Receiver Operating Characteristic**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7NKVF6tvabt"
      },
      "source": [
        "def roc_curve(true,pred):\n",
        "    \n",
        "\n",
        "    thresholds = np.array(list(range(0,100,10)))/100\n",
        "    roc = []\n",
        "    for threshold in thresholds:\n",
        "        true_positive,false_negative,true_negative,false_positive = 0,0,0,0\n",
        "        for actual,predicted  in zip(true,pred):\n",
        "            # print(actual,predicted,threshold)\n",
        "            if predicted > threshold:\n",
        "                class_ = 1\n",
        "            else:\n",
        "                class_ = 0\n",
        "\n",
        "            if actual == 1 and predicted == 1:\n",
        "                true_positive +=1\n",
        "            elif actual == 1 and predicted ==0:\n",
        "                false_negative +=1\n",
        "            elif actual == 0 and predicted == 0:\n",
        "                true_negative +=1\n",
        "            else:\n",
        "                false_positive+=1\n",
        "\n",
        "        print(true_negative,true_positive,false_positive,false_negative)\n",
        "        try:\n",
        "            true_positive_rate = true_positive/(false_negative + true_positive)\n",
        "            false_positve_rate = false_positive/(false_negative + true_positive)\n",
        "            precision = true_positive / (true_positive + false_positive)\n",
        "            roc.append([threshold,true_positive_rate,false_positve_rate,precision])\n",
        "        except Exception as e:\n",
        "            print(str(e),roc)\n",
        "            pass\n",
        "            \n",
        "        \n",
        "    \n",
        "    return roc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qD8hUrGmzIOD"
      },
      "source": [
        "**AUC - Area Under the Curve**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpQr2R-GzdlM"
      },
      "source": [
        "def auc(roc):\n",
        "    auc_val= np.trapz(true_positive_rate,false_positve_rate)\n",
        "    return  (round(abs(auc_val)),2)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yt1qKYXAX-b"
      },
      "source": [
        "# model = torch.load()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hy6WTNt29a1u",
        "outputId": "0524cf89-b997-4516-e142-c63f07570b3c"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-eFr93AK0mj"
      },
      "source": [
        "# **Input data: Review Data** \n",
        "\n",
        "I have placed a pickle file of the review_data.csv in my github\n",
        "\n",
        "You can even upload the csv file by browing you file system and uploading it\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIqys8V-y23S",
        "outputId": "0c40c2a0-32ab-49de-bba8-48641109cc45"
      },
      "source": [
        "\n",
        "if os.path.exists('/content/review_data.csv'):\n",
        "    #if already uploaded read from here\n",
        "    with open('/content/review_data.csv', 'r') as f:\n",
        "        sentiment_data = pd.read_csv(f,header=0)\n",
        "else:\n",
        "\n",
        "    try:\n",
        "        sentiment_data = pd.read_parquet(\"https://github.com/Srigowri/AssignmentDatasets/blob/master/review_parquet.gzip?raw=true\")\n",
        "    except:\n",
        "        from google.colab import files\n",
        "        import io\n",
        "        #upload if not present\n",
        "        print(\"File not present,please upload by selecting the file\")\n",
        "        from google.colab import files\n",
        "        sentiment_file = files.upload()\n",
        "        print(sentiment_file.keys())\n",
        "        sentiment_data = pd.read_csv(io.BytesIO(sentiment_file['review_data.csv']))\n",
        "print(\"Number of reviews in the csv\",len(sentiment_data))\n",
        "print(\"Fields in the CSV data\",sentiment_data.columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of reviews in the csv 50000\n",
            "Fields in the CSV data Index(['final_review', 'sentiment'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swXAsK-2MkUp",
        "outputId": "fb04d7d1-9b47-4144-8935-28da1a5e16b0"
      },
      "source": [
        "print(tabulate(sentiment_data.head(), headers=\"firstrow\", tablefmt=\"grid\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
            "|   0 | teenager martha moxley maggie grace moves high class area belle greenwich connecticut mischief night eve halloween murdered backyard house murder remained unsolved twenty two years later writer mark fuhrman christopher meloni former la detective fallen disgrace perjury j simpson trial moved idaho decides investigate case partner stephen weeks andrew mitchell purpose writing book locals squirm welcome support retired detective steve carroll robert forster charge investigation discover criminal net power money cover murder murder greenwich good tv movie true story murder fifteen years old girl committed wealthy teenager whose mother kennedy powerful rich family used influence cover murder twenty years however snoopy detective convicted perjurer disgrace able disclose hideous crime committed screenplay shows investigation mark last days martha parallel lack emotion dramatization vote seven title brazil available                                                                                        |   1 |\n",
            "+=====+===================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================+=====+\n",
            "|   1 | ok really like kris kristofferson usual easy going delivery lines movies age helped soft spoken low energy style steal scene effortlessly disappearance misstep holy moly bad movie must give kudos cinematography actors including kris trying darndest make sense goofy confusing story none made sense kris probably understand either going motions hoping someone would come tell care everyone movie love project nonsense seen low budget movies plot goodness sake none zilcho nada zippo empty reason complete waste good talent scenery celluloid rented piece garbage buck want money back want hours back invested grade f waste time watch movie waste minute valuable time passing room playing even open case holding dvd believe thank advice                                                                                                                                                                                                                                                                                     |   0 |\n",
            "+-----+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
            "|   2 | spoiler read think watching movie although would waste time way plot predictable make difference read anyway wondering whether see coyote ugly worth either money ticket vhs dvd typical chick feel good flick one could say plot shallow ridiculous uncritical version american dream young good looking girl small town becoming big success new york desperate attempts giving movie depth fail tragic accident father difficulties violet relationship boyfriend mcnally director tries arouse audience pity sadness put chance succeed attempt due bad script shallow acting especially piper perabo completely fails convincing one jersey fear singing front audience good quite funny thing coyote ugly john goodman represents small ray hope movie astonished jerry bruckheimer produced movie first gone seconds happened great movies like rock con air true bruckheimer stuff looking superficial movie good looking women relaxed evening better go see charlie angels much funny entertaining self ironic instead flick two thumbs |   0 |\n",
            "+-----+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
            "|   3 | hi people seen wonderful movie im sure thet would liked much love songs seen show sing along though part show singing dancing dancing singing song one time fave musical song strutters end mirror oh watch one                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |   1 |\n",
            "+-----+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
            "|   4 | recently bought dvd forgetting much hated movie version chorus line every change director attenborough made story failed making director cassie relationship prominent entire ensemble premise musical sails window musical numbers sped rushed show hit song gets entire meaning shattered given cassie character overall staging self conscious reason give great numbers still able enjoyed despite film attempt squeeze every bit joy spontaneity                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |   0 |\n",
            "+-----+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XCu67SCFnne"
      },
      "source": [
        "# **Preprocessing the textual information**\n",
        "\n",
        "\n",
        "\n",
        "Convert to lower case, remove any character other than alphabet and replace the +s with spaces"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pi5kCptAFbok"
      },
      "source": [
        "sentiment_data[\"final_review\"] =  sentiment_data[\"final_review\"].apply(lambda x:x.lower())\n",
        "sentiment_data[\"final_review\"] =  sentiment_data[\"final_review\"].apply(lambda x:re.sub(r\"[^a-z]\",\" \",x))\n",
        "sentiment_data[\"final_review\"] =  sentiment_data[\"final_review\"].apply(lambda x:re.sub(r\" +\",\" \",x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iP_hk4_BLszT"
      },
      "source": [
        "def get_reviews(sentiment_data):\n",
        "    \"\"\"\n",
        "    Input: sentiment_data- pandas a dataframe with final_review and sentiment labels\n",
        "    Output: Split each review sentence to words and return the list of reviews and labels\n",
        "    \"\"\"\n",
        "    reviews = []\n",
        "    labels = []\n",
        "    for index in range(len(sentiment_data)):\n",
        "        review = sentiment_data[\"final_review\"][index].split()\n",
        "        reviews.append(review)\n",
        "        labels.append(sentiment_data[\"sentiment\"][index])\n",
        "    return reviews,labels\n",
        "\n",
        "reviews, labels = get_reviews(sentiment_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4plFPZ-a8jB5"
      },
      "source": [
        "del sentiment_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpuiTpCfPUK5"
      },
      "source": [
        "The neural networks best work with numbers & not with words so we shall translate the textual data into numerical representation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SFEiRR0LGoa"
      },
      "source": [
        "# **GLOVE Embeddings**\n",
        "\n",
        "For this task, I am using a predefined word embeddings called Global vectors.\n",
        "References: https://nlp.stanford.edu/projects/glove/\n",
        "\n",
        "[Word embedding are mappings fOr each word to a vector of features]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmGHjTlKPsxU",
        "outputId": "9cd66f4f-1282-4112-a5a6-602e14a41805"
      },
      "source": [
        "import zipfile\n",
        "import urllib.request as request\n",
        "\n",
        "\n",
        "url = \"https://nlp.stanford.edu/data/glove.6B.zip\"\n",
        "\n",
        "\n",
        "#if already uploaded read from here\n",
        "if not os.path.exists('glove.6B.zip'):\n",
        "    request.urlretrieve(url,\"glove.6B.zip\")\n",
        "\n",
        "embed_size=50\n",
        "\n",
        "if not os.path.exists(\"glove.6B.{}d.txt\".format(embed_size)):\n",
        "    with zipfile.ZipFile(\"glove.6B.zip\",\"r\") as f:\n",
        "        f.extractall()\n",
        "\n",
        "! ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "glove.6B.100d.txt  glove.6B.300d.txt  glove.6B.zip\n",
            "glove.6B.200d.txt  glove.6B.50d.txt   sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_SDtZ9vLNWB"
      },
      "source": [
        "**Review Words to Numbers**\n",
        "\n",
        "A line in a glove file is as follows\n",
        "\n",
        "**< word >  < vector of values >**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BMAwwnJXRzJ",
        "outputId": "85d6158b-b63c-44b3-a143-a483c64f5816"
      },
      "source": [
        "#using defaultdict will let you specify the default value of an unknown hash in this case, any unknown word\n",
        "# word_to_int[\"dsfasdf\"] will be at index 0 and the embedding at index 0 is all 0\n",
        "def get_glove_embeddings(embed_size=50):\n",
        "    \"\"\"\n",
        "    The embedding file has one line per word\n",
        "    Each line has a word and a list of vectors of size embed_size\n",
        "\n",
        "    Output: A dictionary which maps a word to an index and \n",
        "            another dictionary that will map the index to a list of vectors\n",
        "            Eg:\n",
        "            \"cat\" -> 2\n",
        "            \"2\" -> [1.0,2.3,4.0,.....]\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "    from collections import defaultdict\n",
        "\n",
        "    filename = \"glove.6B.{}d.txt\".format(embed_size)\n",
        "    print(\"Getting embeddings from\", filename)\n",
        "\n",
        "    with open(filename,\"r\") as f:\n",
        "        word_to_number = defaultdict(int)\n",
        "        number_to_vector =  defaultdict(lambda: np.zeros([embed_size]))\n",
        "        #starting the index at 1, as 0 will be used for any unknown words in default dict\n",
        "        index = 1\n",
        "        #read every the glove file line by line\n",
        "        for embedding_line in f:\n",
        "            line = embedding_line.split()\n",
        "            word = str(line[0])                      #the first word in the line is a word\n",
        "            vector = np.array(line[1:],np.float32)   #the rest are values\n",
        "            word_to_number[word] = index             #map word to its index\n",
        "            number_to_vector[index] = vector         #map index to vectors\n",
        "            index+=1\n",
        "    return word_to_number,number_to_vector\n",
        "\n",
        "word_to_number, number_to_vector = get_glove_embeddings()\n",
        "print(\"Total number of words\",len(word_to_number))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Getting embeddings from glove.6B.50d.txt\n",
            "Total number of words 400000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVsTiQcecHpm",
        "outputId": "e1e1ab86-70e6-49c8-b971-77df04590958"
      },
      "source": [
        "def get_review_to_num(reviews):\n",
        "    \"\"\"\n",
        "    Input: The given data set whose sentences are split into words\n",
        "    Map every word in the sentence to an index\n",
        "    \"\"\"\n",
        "    reviews_to_num_list = []\n",
        "    for review in reviews:\n",
        "        review_to_num = [word_to_number[word] for word in review]\n",
        "        reviews_to_num_list.append(review_to_num)\n",
        "    return reviews_to_num_list\n",
        "\n",
        "def get_review_to_vec(reviews_to_num_list):\n",
        "    \"\"\"\n",
        "    Input: Review whose words in the sentences are mapped to index\n",
        "    Map every index of the sentence to a vector of values\n",
        "    \"\"\"\n",
        "    reviews_to_vector_list = []\n",
        "    for review  in reviews_to_num_list:\n",
        "        review_to_vector = [number_to_vector[num] for num in review]\n",
        "        reviews_to_vector_list.append(review_to_vector)\n",
        "    return reviews_to_vector_list\n",
        "\n",
        "reviews_to_num_list = get_review_to_num(reviews)\n",
        "\n",
        "print(\"Sentence to words\",reviews[0])\n",
        "print(\"Words to index\",reviews_to_num_list[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence to words ['teenager', 'martha', 'moxley', 'maggie', 'grace', 'moves', 'high', 'class', 'area', 'belle', 'greenwich', 'connecticut', 'mischief', 'night', 'eve', 'halloween', 'murdered', 'backyard', 'house', 'murder', 'remained', 'unsolved', 'twenty', 'two', 'years', 'later', 'writer', 'mark', 'fuhrman', 'christopher', 'meloni', 'former', 'la', 'detective', 'fallen', 'disgrace', 'perjury', 'j', 'simpson', 'trial', 'moved', 'idaho', 'decides', 'investigate', 'case', 'partner', 'stephen', 'weeks', 'andrew', 'mitchell', 'purpose', 'writing', 'book', 'locals', 'squirm', 'welcome', 'support', 'retired', 'detective', 'steve', 'carroll', 'robert', 'forster', 'charge', 'investigation', 'discover', 'criminal', 'net', 'power', 'money', 'cover', 'murder', 'murder', 'greenwich', 'good', 'tv', 'movie', 'true', 'story', 'murder', 'fifteen', 'years', 'old', 'girl', 'committed', 'wealthy', 'teenager', 'whose', 'mother', 'kennedy', 'powerful', 'rich', 'family', 'used', 'influence', 'cover', 'murder', 'twenty', 'years', 'however', 'snoopy', 'detective', 'convicted', 'perjurer', 'disgrace', 'able', 'disclose', 'hideous', 'crime', 'committed', 'screenplay', 'shows', 'investigation', 'mark', 'last', 'days', 'martha', 'parallel', 'lack', 'emotion', 'dramatization', 'vote', 'seven', 'title', 'brazil', 'available']\n",
            "Words to index [7187, 7456, 53221, 15008, 5050, 2479, 153, 906, 238, 11866, 11371, 3806, 23410, 365, 4205, 12000, 5927, 13244, 167, 1476, 1044, 19470, 4450, 56, 83, 169, 1542, 800, 20010, 3258, 114543, 158, 1048, 6635, 3285, 17590, 15603, 6892, 3702, 802, 555, 7858, 6039, 3975, 306, 1916, 2663, 518, 2632, 4303, 2801, 1650, 540, 7183, 56196, 3144, 281, 1661, 6635, 1927, 7715, 894, 26327, 1091, 973, 6315, 1512, 1051, 269, 309, 1334, 1476, 1476, 11371, 220, 817, 1006, 1447, 524, 1476, 7605, 83, 168, 1750, 1806, 4552, 7187, 508, 809, 2298, 1529, 1728, 214, 181, 1730, 1334, 1476, 4450, 83, 213, 44369, 6635, 2136, 180370, 17590, 668, 6973, 31909, 1341, 1806, 9046, 971, 973, 800, 77, 250, 7456, 5380, 1493, 8493, 61026, 539, 439, 699, 1343, 780]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8BRc98ogZvB"
      },
      "source": [
        "Now that we have every word converted to vector\n",
        "What should be the sizes of each input?\n",
        "\n",
        "From the below plots it can be seen that the reviews have varying input sizes\n",
        "The median is less than 200\n",
        "\n",
        "I am fixing the input size to be 500 based on the below box plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "FRabRL7FgaBg",
        "outputId": "01402bf9-d821-45fc-882c-d02a266d7a2b"
      },
      "source": [
        "len_per_review = [len(review) for review in reviews]\n",
        "\n",
        "fig,axes =  plt.subplots(1,2,figsize=(16,6))\n",
        "axes[0].hist(len_per_review,bins = 200)\n",
        "axes[0].set_title(\"Distribution of word lengths\")\n",
        "axes[1].boxplot(len_per_review)\n",
        "axes[1].set_title(\"Box plot of review lengths\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7h_8-YGFRKh"
      },
      "source": [
        "del len_per_review\n",
        "for val in [50,100,200,300]:\n",
        "    os.remove(\"glove.6B.{}d.txt\".format(val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRuxifxsLZD6"
      },
      "source": [
        "# **Max len of a sentence**\n",
        "\n",
        "Based on the above box blot, I am selecting the maximum length of the sentence to be 500 words\n",
        "Any thing greater will be truncated,\n",
        "anything lesser will have the default index 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRKu_w4bj9zV"
      },
      "source": [
        "def trucate_or_pad(reviews_to_num_list,max_length = 500):\n",
        "    for index,review in enumerate(reviews_to_num_list):\n",
        "        paddings = [0]*max_length\n",
        "        end = min(max_length,len(review))\n",
        "        paddings[:end] = review[:end]\n",
        "        reviews_to_num_list[index] = paddings\n",
        "    return reviews_to_num_list\n",
        "\n",
        "max_length = 500\n",
        "reviews_to_num_list = trucate_or_pad(reviews_to_num_list)\n",
        "reviews_to_vector_list = get_review_to_vec(reviews_to_num_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVHdloN40GEA"
      },
      "source": [
        "# import pickle\n",
        "\n",
        "# with open(\"reviews_to_vector.pkl\",\"w\") as f:\n",
        "#     pickle.dump(str(reviews_to_vector_list),f)\n",
        "\n",
        "\n",
        "# with open(\"labels.pkl\",\"w\") as f:\n",
        "#     pickle.dump(str(labels),f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDGzkBPF7Iz9",
        "outputId": "e7efb2c0-99dd-40db-e8e2-7bf591465514"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "am-WEc3SLdl5"
      },
      "source": [
        "# **Splitting data 80-10-10**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImP01XPdr-6l",
        "outputId": "64a72938-790a-4879-9238-59f6059898b0"
      },
      "source": [
        "from sklearn.model_selection  import train_test_split\n",
        "trainx,testx,trainy,testy = train_test_split(reviews_to_vector_list,labels,test_size=0.1,shuffle=True)\n",
        "trainx,valx,trainy,valy = train_test_split(trainx,trainy,test_size=len(testx)/len(trainx),shuffle=True)\n",
        "print(\"Length of trainx\",len(trainx))\n",
        "print(\"Length of testx\",len(testx))\n",
        "print(\"Length of valx\",len(valx))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of trainx 40000\n",
            "Length of testx 5000\n",
            "Length of valx 5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwT47CVP8tZq",
        "outputId": "da31b3d7-610b-4c77-8bb8-39266f94e55f"
      },
      "source": [
        "del labels\n",
        "del reviews\n",
        "del reviews_to_vector_list\n",
        "del reviews_to_num_list\n",
        "del word_to_number\n",
        "del number_to_vector\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFLXR3QSLjRg"
      },
      "source": [
        "**Iterable batches**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQXzU08J_5WD",
        "outputId": "ac8a410a-d0f7-4513-b5cb-5104642e046a"
      },
      "source": [
        "batchSize = 16\n",
        "\n",
        "valx = torch.tensor(valx,dtype=torch.float32)\n",
        "valy = torch.tensor(valy,dtype=torch.float32)\n",
        "valLoader = torch.utils.data.DataLoader(dataset=torch.utils.data.TensorDataset(valx,valy),\n",
        "                                           batch_size=batchSize)\n",
        "del valx\n",
        "del valy\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOL0o3wvx8v2",
        "outputId": "174c4f64-0e41-4e10-d5c2-ee7711136d63"
      },
      "source": [
        "batchSize = 16\n",
        "\n",
        "trainx = torch.tensor(trainx,dtype=torch.float32)\n",
        "trainy= torch.tensor(trainy,dtype=torch.float32)\n",
        "\n",
        "\n",
        "#using torch's utility function to load data in batches\n",
        "trainLoader = torch.utils.data.DataLoader(dataset=torch.utils.data.TensorDataset(trainx,trainy),\n",
        "                                           batch_size=batchSize,                                     \n",
        "                                         )\n",
        "\n",
        "del trainx\n",
        "del trainy\n",
        "gc.collect()\n",
        "print(\"Number of training examples   = \",len(trainLoader)*batchSize)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples   =  40000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfMx0xLfD89v",
        "outputId": "13bba1e7-4dc5-4be6-bf8d-28defcf111b2"
      },
      "source": [
        "! pip3 install guppy3\n",
        "from guppy import hpy\n",
        "\n",
        "h = hpy()\n",
        "print(h.heap() )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting guppy3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/8f/ae8ddf9a61491d64c4e16871225b30bf2524d0e54d2d8354852e6b066947/guppy3-3.1.0-cp36-cp36m-manylinux2010_x86_64.whl (605kB)\n",
            "\r\u001b[K     |                               | 10kB 25.1MB/s eta 0:00:01\r\u001b[K     |                               | 20kB 13.4MB/s eta 0:00:01\r\u001b[K     |                              | 30kB 12.3MB/s eta 0:00:01\r\u001b[K     |                             | 40kB 11.5MB/s eta 0:00:01\r\u001b[K     |                             | 51kB 7.7MB/s eta 0:00:01\r\u001b[K     |                            | 61kB 8.4MB/s eta 0:00:01\r\u001b[K     |                            | 71kB 8.3MB/s eta 0:00:01\r\u001b[K     |                           | 81kB 8.6MB/s eta 0:00:01\r\u001b[K     |                           | 92kB 8.7MB/s eta 0:00:01\r\u001b[K     |                          | 102kB 7.5MB/s eta 0:00:01\r\u001b[K     |                          | 112kB 7.5MB/s eta 0:00:01\r\u001b[K     |                         | 122kB 7.5MB/s eta 0:00:01\r\u001b[K     |                         | 133kB 7.5MB/s eta 0:00:01\r\u001b[K     |                        | 143kB 7.5MB/s eta 0:00:01\r\u001b[K     |                       | 153kB 7.5MB/s eta 0:00:01\r\u001b[K     |                       | 163kB 7.5MB/s eta 0:00:01\r\u001b[K     |                      | 174kB 7.5MB/s eta 0:00:01\r\u001b[K     |                      | 184kB 7.5MB/s eta 0:00:01\r\u001b[K     |                     | 194kB 7.5MB/s eta 0:00:01\r\u001b[K     |                     | 204kB 7.5MB/s eta 0:00:01\r\u001b[K     |                    | 215kB 7.5MB/s eta 0:00:01\r\u001b[K     |                    | 225kB 7.5MB/s eta 0:00:01\r\u001b[K     |                   | 235kB 7.5MB/s eta 0:00:01\r\u001b[K     |                   | 245kB 7.5MB/s eta 0:00:01\r\u001b[K     |                  | 256kB 7.5MB/s eta 0:00:01\r\u001b[K     |                  | 266kB 7.5MB/s eta 0:00:01\r\u001b[K     |                 | 276kB 7.5MB/s eta 0:00:01\r\u001b[K     |                | 286kB 7.5MB/s eta 0:00:01\r\u001b[K     |                | 296kB 7.5MB/s eta 0:00:01\r\u001b[K     |               | 307kB 7.5MB/s eta 0:00:01\r\u001b[K     |               | 317kB 7.5MB/s eta 0:00:01\r\u001b[K     |              | 327kB 7.5MB/s eta 0:00:01\r\u001b[K     |              | 337kB 7.5MB/s eta 0:00:01\r\u001b[K     |             | 348kB 7.5MB/s eta 0:00:01\r\u001b[K     |             | 358kB 7.5MB/s eta 0:00:01\r\u001b[K     |            | 368kB 7.5MB/s eta 0:00:01\r\u001b[K     |            | 378kB 7.5MB/s eta 0:00:01\r\u001b[K     |           | 389kB 7.5MB/s eta 0:00:01\r\u001b[K     |          | 399kB 7.5MB/s eta 0:00:01\r\u001b[K     |          | 409kB 7.5MB/s eta 0:00:01\r\u001b[K     |         | 419kB 7.5MB/s eta 0:00:01\r\u001b[K     |         | 430kB 7.5MB/s eta 0:00:01\r\u001b[K     |        | 440kB 7.5MB/s eta 0:00:01\r\u001b[K     |        | 450kB 7.5MB/s eta 0:00:01\r\u001b[K     |       | 460kB 7.5MB/s eta 0:00:01\r\u001b[K     |       | 471kB 7.5MB/s eta 0:00:01\r\u001b[K     |      | 481kB 7.5MB/s eta 0:00:01\r\u001b[K     |      | 491kB 7.5MB/s eta 0:00:01\r\u001b[K     |     | 501kB 7.5MB/s eta 0:00:01\r\u001b[K     |     | 512kB 7.5MB/s eta 0:00:01\r\u001b[K     |    | 522kB 7.5MB/s eta 0:00:01\r\u001b[K     |   | 532kB 7.5MB/s eta 0:00:01\r\u001b[K     |   | 542kB 7.5MB/s eta 0:00:01\r\u001b[K     |  | 552kB 7.5MB/s eta 0:00:01\r\u001b[K     |  | 563kB 7.5MB/s eta 0:00:01\r\u001b[K     | | 573kB 7.5MB/s eta 0:00:01\r\u001b[K     | | 583kB 7.5MB/s eta 0:00:01\r\u001b[K     || 593kB 7.5MB/s eta 0:00:01\r\u001b[K     || 604kB 7.5MB/s eta 0:00:01\r\u001b[K     || 614kB 7.5MB/s \n",
            "\u001b[?25hInstalling collected packages: guppy3\n",
            "Successfully installed guppy3-3.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/distributed/distributed_c10d.py:126: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
            "  warnings.warn(\"torch.distributed.reduce_op is deprecated, please use \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Partition of a set of 783128 objects. Total size = 125963352 bytes.\n",
            " Index  Count   %     Size   % Cumulative  % Kind (class / dict of class)\n",
            "     0 196779  25 28640698  23  28640698  23 str\n",
            "     1  15354   2 22776608  18  51417306  41 list\n",
            "     2 197746  25 15299840  12  66717146  53 tuple\n",
            "     3  38477   5 10865411   9  77582557  62 numpy.ndarray\n",
            "     4  82507  11  6568197   5  84150754  67 bytes\n",
            "     5  42112   5  6094240   5  90244994  72 types.CodeType\n",
            "     6  41973   5  5708328   5  95953322  76 function\n",
            "     7  15850   2  5443336   4 101396658  80 dict (no owner)\n",
            "     8   4651   1  4555248   4 105951906  84 type\n",
            "     9   1931   0  2934032   2 108885938  86 dict of module\n",
            "<1803 more rows. Type e.g. '_.more' to view.>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a49-iSVX9O7z",
        "outputId": "fe99cd8c-9a9b-4b60-8617-7a74184d85ef"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7568"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrkTJa_ezRFs",
        "outputId": "53d53f92-dbf9-4fac-b949-763d6c84ffe5"
      },
      "source": [
        "batchSize = 16\n",
        "\n",
        "testx = torch.tensor(testx,dtype=torch.float32)\n",
        "testy = torch.tensor(testy,dtype=torch.float32)\n",
        "testLoader = torch.utils.data.DataLoader(dataset=torch.utils.data.TensorDataset(testx,testy),\n",
        "                                          batch_size=batchSize)\n",
        "\n",
        "del testx\n",
        "del testy\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dtuH5X1WraV"
      },
      "source": [
        "path = \"/content/\"\n",
        "filename = \"first_run\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8rL5c6QoXUU",
        "outputId": "057a2b5d-ac8c-4e24-f6f9-61b928009856"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68Jc0GC_sIkf"
      },
      "source": [
        "# drive.flush_and_unmount()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGSf4eKizwIo"
      },
      "source": [
        "Reference for the last layers of BLSTM:\n",
        "https://towardsdatascience.com/understanding-bidirectional-rnn-in-pytorch-5bd25a5dd66"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KI8wzLoLpCk"
      },
      "source": [
        "# **Bidirection**\n",
        "\n",
        "\n",
        "I am taking the average of the forward (last sequence) and backward(first sequence) and passing it to the final classification layer which is fully connected layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wizgywXA93pN"
      },
      "source": [
        "class BIDIRECTIONAL_LSTM(nn.Module):\n",
        "    def __init__(self,input_size,sequence_length,hidden_size,num_layers,num_classes,batch_size,batch_first=False):\n",
        "        super(BIDIRECTIONAL_LSTM,self).__init__()\n",
        "        self.input_size = input_size     #size of the word embedding\n",
        "        self.hidden_size=hidden_size     #size of the hidden layer\n",
        "        self.num_layers=num_layers       #if the lstm is stacked\n",
        "        self.batch_first=batch_first     #if the batch_size is the first dimension or sequence len\n",
        "        self.batch_size = batch_size\n",
        "        self.sequence_length = sequence_length\n",
        "\n",
        "        #input size will be the size of the inputs x1,...xn\n",
        "        #hidden state has hidden_size\n",
        "        self.bidirLSTM = torch.nn.LSTM(input_size,hidden_size,num_layers,batch_first,dropout = 0.5,bidirectional=True)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fullyconnected = nn.Linear(hidden_size,num_classes)\n",
        "    def forward(self,x):\n",
        "        #initialze the weights to 0, for every element in the batch\n",
        "        #num_layer,batch_size, hidden_size\n",
        "        \n",
        "        #x.size(1) is the batch size\n",
        "        h_0 = torch.zeros(self.num_layers*2,x.size(1),self.hidden_size).to(device)\n",
        "#         print(h_0.shape)\n",
        "        c_0 = torch.zeros(self.num_layers*2,x.size(1),self.hidden_size).to(device)\n",
        "        # seqlen,batch, hidden_size*2\n",
        "        out, (h_n,c_n) = self.bidirLSTM(x,(h_0,c_0))\n",
        "        #seq,batch,  hidden\n",
        "        # print(\"befor\",out.shape)\n",
        "        outview = out.contiguous().view(self.sequence_length,-1, 2, self.hidden_size)\n",
        "        #seq batch 2 hidden\n",
        "        forward = outview[-1,:,0,:]     #-1 = last node/sequence 0 = forward \n",
        "        backward = outview[0,:,1,:]     #0 =  first node/sequence 1 = backward              \n",
        "        \n",
        "        #taking average of the forward and the backward passes\n",
        "        out = torch.add(input=forward, other=backward,alpha=1,)\n",
        "        out = torch.div(out, 2)\n",
        "\n",
        "        # out = outview[-1,:,0,:]\n",
        "        out = out.contiguous().view(-1, self.hidden_size)        \n",
        "        out = self.fullyconnected(out)\n",
        "        # print(out.shape)\n",
        "        # out = torch.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XntG1A1QRYE_"
      },
      "source": [
        "batch_size = 16\n",
        "sequence_length = max_length #500\n",
        "input_size = embed_size #50\n",
        "hidden_size = 128\n",
        "num_layers = 2\n",
        "num_classes = 2\n",
        "\n",
        "#to use gpu\n",
        "model = BIDIRECTIONAL_LSTM(input_size,sequence_length, hidden_size, num_layers, num_classes,batch_size).to(device)\n",
        "\n",
        "    \n",
        "learning_rate = 0.003\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNAH2KdfOh8O",
        "outputId": "cdc9c8b3-bf20-4968-940a-dd61ea1b6103"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoG8DLnOM4ZD"
      },
      "source": [
        "# ***Training ***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPlmRFaz-NJW",
        "outputId": "2db5c613-7d82-4e0f-80ba-835c1ed181f6"
      },
      "source": [
        "epoch,nEpochs = 0,15\n",
        "log_interval = 100  #step size\n",
        "\n",
        "dataset_size = len(trainLoader.dataset) #number of reviews in training dataset\n",
        "valdata_size = len(valLoader.dataset) #number of reviews in validation dataset\n",
        "best_accuracy = math.inf\n",
        "trainLosses,trainAccuracy,validationAccuracy = [],[],[]\n",
        "validationLoss =[]\n",
        "clip =5\n",
        "# fig,axes = plt.subplots(1,4,figsize=(25,6))\n",
        "start = time.time()\n",
        "\n",
        "while epoch <= nEpochs:# and not stop_training:\n",
        "\n",
        "    model.train()\n",
        "    running_corrects = 0\n",
        "    running_loss = 0\n",
        "    batch = 0\n",
        "    for batch_num, (seq, labels) in enumerate(trainLoader):\n",
        "        # seq = seq.reshape(sequence_length,batch_size ,input_size).to(device)\n",
        "        seq = seq.reshape(sequence_length,-1 ,input_size).to(device)  #the batch size might not be same as batch_size for the last batch\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(seq).to(device)\n",
        "        _,predictions =  torch.max(outputs, 1) #max of the final layer \n",
        "        running_corrects += (torch.sum(predictions==labels).item()) #number of right predicitions         \n",
        "        \n",
        "        #backpropagate\n",
        "        with torch.set_grad_enabled(True):\n",
        "            loss = criterion(outputs, labels.long())\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "            optimizer.step()\n",
        "\n",
        "        loss_value = loss.detach().item()\n",
        "        running_loss += loss_value\n",
        "        # batch += len(trainLoader)\n",
        "        if batch_num % log_interval == 0:  #at step size, output batch loss        \n",
        "            print('Training Epoch: {0}[{1}/{2} sentences]\\\n",
        "            Training Loss: {3:.6f}'.format(epoch+1, batch_num * batch_size,dataset_size,loss_value))   \n",
        "    trainAccuracy.append(running_corrects/len(trainLoader))\n",
        "    trainLosses.append(running_loss/len(trainLoader))\n",
        "\n",
        "\n",
        "    #validation\n",
        "    model.eval()\n",
        "    with torch.set_grad_enabled(False):  #gradient not backpack propagated\n",
        "        val_losses = 0\n",
        "        val_accuracy = 0\n",
        "        for _, (val_batch, val_labels ) in enumerate(valLoader):                    \n",
        "            # val_batch = val_batch.reshape(sequence_length,batch_size ,input_size).to(device)\n",
        "            val_batch = val_batch.reshape(sequence_length,-1 ,input_size).to(device)\n",
        "            val_labels = val_labels.to(device)\n",
        "            val_outputs = model(val_batch).to(device)\n",
        "            #find the average loss and the total loss\n",
        "            val_losses+=(criterion(val_outputs, val_labels.long()).item())\n",
        "\n",
        "            _, val_predictions = torch.max(val_outputs, 1)\n",
        "            val_accuracy+=(torch.sum(val_predictions==val_labels).item() )\n",
        "\n",
        "        validationAccuracy.append(val_accuracy/len(valLoader)) \n",
        "        validationLoss.append(val_losses/len(valLoader))\n",
        "\n",
        "    print('After Epoch: {0}\\\n",
        "            Training Loss: {1:.6f}\\\n",
        "            Training Accuracy {2:.6f}\\\n",
        "            Validation Loss: {3:.6f}\\\n",
        "            Validation Accuracy {4:.6f}'.format(epoch+1,trainLosses[-1],trainAccuracy[-1],validationLoss[-1],validationAccuracy[-1])) \n",
        "        \n",
        "    \n",
        "    if validationAccuracy[-1] > best_accuracy:\n",
        "            best_Accuracy = validationAccuracy[-1]\n",
        "            best_model_weights = copy.deepcopy(model.state_dict())            \n",
        "            torch.save(best_model_weights, path+filename+\".pt\") \n",
        "    with open(path+filename+\".pkl\",\"wb\") as f:\n",
        "        pickle.dump([trainLosses,trainAccuracy,validationAccuracy],f)\n",
        "                                 \n",
        "    # axes[0].plot(trainLosses,label=\"Training loss\")\n",
        "    # axes[1].plot(validationLoss,label=\"Validation loss\")\n",
        "    # axes[3].plot(validationAccuracy,label=\"Validation accuracy\")\n",
        "    # axes[2].plot(trainAccuracy,label=\"Training accuracy\")\n",
        "    \n",
        "    epoch = epoch + 1\n",
        "    \n",
        "end = time.time()\n",
        "# plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Epoch: 1[0/40000 sentences]            Training Loss: 0.691497\n",
            "Training Epoch: 1[1600/40000 sentences]            Training Loss: 0.685882\n",
            "Training Epoch: 1[3200/40000 sentences]            Training Loss: 0.695251\n",
            "Training Epoch: 1[4800/40000 sentences]            Training Loss: 0.701367\n",
            "Training Epoch: 1[6400/40000 sentences]            Training Loss: 0.717480\n",
            "Training Epoch: 1[8000/40000 sentences]            Training Loss: 0.691240\n",
            "Training Epoch: 1[9600/40000 sentences]            Training Loss: 0.692179\n",
            "Training Epoch: 1[11200/40000 sentences]            Training Loss: 0.685556\n",
            "Training Epoch: 1[12800/40000 sentences]            Training Loss: 0.692602\n",
            "Training Epoch: 1[14400/40000 sentences]            Training Loss: 0.697843\n",
            "Training Epoch: 1[16000/40000 sentences]            Training Loss: 0.676955\n",
            "Training Epoch: 1[17600/40000 sentences]            Training Loss: 0.699188\n",
            "Training Epoch: 1[19200/40000 sentences]            Training Loss: 0.693417\n",
            "Training Epoch: 1[20800/40000 sentences]            Training Loss: 0.686014\n",
            "Training Epoch: 1[22400/40000 sentences]            Training Loss: 0.689452\n",
            "Training Epoch: 1[24000/40000 sentences]            Training Loss: 0.675195\n",
            "Training Epoch: 1[25600/40000 sentences]            Training Loss: 0.695183\n",
            "Training Epoch: 1[27200/40000 sentences]            Training Loss: 0.686197\n",
            "Training Epoch: 1[28800/40000 sentences]            Training Loss: 0.692691\n",
            "Training Epoch: 1[30400/40000 sentences]            Training Loss: 0.692638\n",
            "Training Epoch: 1[32000/40000 sentences]            Training Loss: 0.694841\n",
            "Training Epoch: 1[33600/40000 sentences]            Training Loss: 0.693837\n",
            "Training Epoch: 1[35200/40000 sentences]            Training Loss: 0.696533\n",
            "Training Epoch: 1[36800/40000 sentences]            Training Loss: 0.692194\n",
            "Training Epoch: 1[38400/40000 sentences]            Training Loss: 0.712375\n",
            "After Epoch: 1            Training Loss: 0.694450            Training Accuracy 8.044400            Validation Loss: 0.694082            Validation Accuracy 7.805112\n",
            "Training Epoch: 2[0/40000 sentences]            Training Loss: 0.689816\n",
            "Training Epoch: 2[1600/40000 sentences]            Training Loss: 0.696858\n",
            "Training Epoch: 2[3200/40000 sentences]            Training Loss: 0.696980\n",
            "Training Epoch: 2[4800/40000 sentences]            Training Loss: 0.701751\n",
            "Training Epoch: 2[6400/40000 sentences]            Training Loss: 0.718207\n",
            "Training Epoch: 2[8000/40000 sentences]            Training Loss: 0.687804\n",
            "Training Epoch: 2[9600/40000 sentences]            Training Loss: 0.693403\n",
            "Training Epoch: 2[11200/40000 sentences]            Training Loss: 0.690475\n",
            "Training Epoch: 2[12800/40000 sentences]            Training Loss: 0.697003\n",
            "Training Epoch: 2[14400/40000 sentences]            Training Loss: 0.686542\n",
            "Training Epoch: 2[16000/40000 sentences]            Training Loss: 0.680300\n",
            "Training Epoch: 2[17600/40000 sentences]            Training Loss: 0.690714\n",
            "Training Epoch: 2[19200/40000 sentences]            Training Loss: 0.684461\n",
            "Training Epoch: 2[20800/40000 sentences]            Training Loss: 0.691440\n",
            "Training Epoch: 2[22400/40000 sentences]            Training Loss: 0.691672\n",
            "Training Epoch: 2[24000/40000 sentences]            Training Loss: 0.695715\n",
            "Training Epoch: 2[25600/40000 sentences]            Training Loss: 0.697485\n",
            "Training Epoch: 2[27200/40000 sentences]            Training Loss: 0.690787\n",
            "Training Epoch: 2[28800/40000 sentences]            Training Loss: 0.695780\n",
            "Training Epoch: 2[30400/40000 sentences]            Training Loss: 0.691880\n",
            "Training Epoch: 2[32000/40000 sentences]            Training Loss: 0.690548\n",
            "Training Epoch: 2[33600/40000 sentences]            Training Loss: 0.690354\n",
            "Training Epoch: 2[35200/40000 sentences]            Training Loss: 0.688386\n",
            "Training Epoch: 2[36800/40000 sentences]            Training Loss: 0.686318\n",
            "Training Epoch: 2[38400/40000 sentences]            Training Loss: 0.713264\n",
            "After Epoch: 2            Training Loss: 0.693760            Training Accuracy 7.977200            Validation Loss: 0.693993            Validation Accuracy 7.821086\n",
            "Training Epoch: 3[0/40000 sentences]            Training Loss: 0.686500\n",
            "Training Epoch: 3[1600/40000 sentences]            Training Loss: 0.691906\n",
            "Training Epoch: 3[3200/40000 sentences]            Training Loss: 0.703322\n",
            "Training Epoch: 3[4800/40000 sentences]            Training Loss: 0.697670\n",
            "Training Epoch: 3[6400/40000 sentences]            Training Loss: 0.707935\n",
            "Training Epoch: 3[8000/40000 sentences]            Training Loss: 0.692001\n",
            "Training Epoch: 3[9600/40000 sentences]            Training Loss: 0.686429\n",
            "Training Epoch: 3[11200/40000 sentences]            Training Loss: 0.689243\n",
            "Training Epoch: 3[12800/40000 sentences]            Training Loss: 0.687053\n",
            "Training Epoch: 3[14400/40000 sentences]            Training Loss: 0.698387\n",
            "Training Epoch: 3[16000/40000 sentences]            Training Loss: 0.681764\n",
            "Training Epoch: 3[17600/40000 sentences]            Training Loss: 0.698362\n",
            "Training Epoch: 3[19200/40000 sentences]            Training Loss: 0.699232\n",
            "Training Epoch: 3[20800/40000 sentences]            Training Loss: 0.702266\n",
            "Training Epoch: 3[22400/40000 sentences]            Training Loss: 0.694809\n",
            "Training Epoch: 3[24000/40000 sentences]            Training Loss: 0.683656\n",
            "Training Epoch: 3[25600/40000 sentences]            Training Loss: 0.697795\n",
            "Training Epoch: 3[27200/40000 sentences]            Training Loss: 0.687868\n",
            "Training Epoch: 3[28800/40000 sentences]            Training Loss: 0.699702\n",
            "Training Epoch: 3[30400/40000 sentences]            Training Loss: 0.691683\n",
            "Training Epoch: 3[32000/40000 sentences]            Training Loss: 0.684384\n",
            "Training Epoch: 3[33600/40000 sentences]            Training Loss: 0.686690\n",
            "Training Epoch: 3[35200/40000 sentences]            Training Loss: 0.679319\n",
            "Training Epoch: 3[36800/40000 sentences]            Training Loss: 0.672325\n",
            "Training Epoch: 3[38400/40000 sentences]            Training Loss: 0.696339\n",
            "After Epoch: 3            Training Loss: 0.693812            Training Accuracy 8.029600            Validation Loss: 0.693557            Validation Accuracy 7.808307\n",
            "Training Epoch: 4[0/40000 sentences]            Training Loss: 0.676630\n",
            "Training Epoch: 4[1600/40000 sentences]            Training Loss: 0.676390\n",
            "Training Epoch: 4[3200/40000 sentences]            Training Loss: 0.695327\n",
            "Training Epoch: 4[4800/40000 sentences]            Training Loss: 0.708355\n",
            "Training Epoch: 4[6400/40000 sentences]            Training Loss: 0.708011\n",
            "Training Epoch: 4[8000/40000 sentences]            Training Loss: 0.695112\n",
            "Training Epoch: 4[9600/40000 sentences]            Training Loss: 0.695210\n",
            "Training Epoch: 4[11200/40000 sentences]            Training Loss: 0.692290\n",
            "Training Epoch: 4[12800/40000 sentences]            Training Loss: 0.696084\n",
            "Training Epoch: 4[14400/40000 sentences]            Training Loss: 0.690598\n",
            "Training Epoch: 4[16000/40000 sentences]            Training Loss: 0.680532\n",
            "Training Epoch: 4[17600/40000 sentences]            Training Loss: 0.685384\n",
            "Training Epoch: 4[19200/40000 sentences]            Training Loss: 0.690036\n",
            "Training Epoch: 4[20800/40000 sentences]            Training Loss: 0.693439\n",
            "Training Epoch: 4[22400/40000 sentences]            Training Loss: 0.688605\n",
            "Training Epoch: 4[24000/40000 sentences]            Training Loss: 0.698871\n",
            "Training Epoch: 4[25600/40000 sentences]            Training Loss: 0.693042\n",
            "Training Epoch: 4[27200/40000 sentences]            Training Loss: 0.692996\n",
            "Training Epoch: 4[28800/40000 sentences]            Training Loss: 0.691639\n",
            "Training Epoch: 4[30400/40000 sentences]            Training Loss: 0.688979\n",
            "Training Epoch: 4[32000/40000 sentences]            Training Loss: 0.684451\n",
            "Training Epoch: 4[33600/40000 sentences]            Training Loss: 0.688182\n",
            "Training Epoch: 4[35200/40000 sentences]            Training Loss: 0.680833\n",
            "Training Epoch: 4[36800/40000 sentences]            Training Loss: 0.672016\n",
            "Training Epoch: 4[38400/40000 sentences]            Training Loss: 0.691632\n",
            "After Epoch: 4            Training Loss: 0.693633            Training Accuracy 8.000800            Validation Loss: 0.694781            Validation Accuracy 7.907348\n",
            "Training Epoch: 5[0/40000 sentences]            Training Loss: 0.698334\n",
            "Training Epoch: 5[1600/40000 sentences]            Training Loss: 0.686913\n",
            "Training Epoch: 5[3200/40000 sentences]            Training Loss: 0.709048\n",
            "Training Epoch: 5[4800/40000 sentences]            Training Loss: 0.690310\n",
            "Training Epoch: 5[6400/40000 sentences]            Training Loss: 0.709056\n",
            "Training Epoch: 5[8000/40000 sentences]            Training Loss: 0.710310\n",
            "Training Epoch: 5[9600/40000 sentences]            Training Loss: 0.681274\n",
            "Training Epoch: 5[11200/40000 sentences]            Training Loss: 0.687667\n",
            "Training Epoch: 5[12800/40000 sentences]            Training Loss: 0.692319\n",
            "Training Epoch: 5[14400/40000 sentences]            Training Loss: 0.690149\n",
            "Training Epoch: 5[16000/40000 sentences]            Training Loss: 0.684116\n",
            "Training Epoch: 5[17600/40000 sentences]            Training Loss: 0.689509\n",
            "Training Epoch: 5[19200/40000 sentences]            Training Loss: 0.701598\n",
            "Training Epoch: 5[20800/40000 sentences]            Training Loss: 0.692113\n",
            "Training Epoch: 5[22400/40000 sentences]            Training Loss: 0.683880\n",
            "Training Epoch: 5[24000/40000 sentences]            Training Loss: 0.683581\n",
            "Training Epoch: 5[25600/40000 sentences]            Training Loss: 0.691942\n",
            "Training Epoch: 5[27200/40000 sentences]            Training Loss: 0.696884\n",
            "Training Epoch: 5[28800/40000 sentences]            Training Loss: 0.691756\n",
            "Training Epoch: 5[30400/40000 sentences]            Training Loss: 0.695223\n",
            "Training Epoch: 5[32000/40000 sentences]            Training Loss: 0.680225\n",
            "Training Epoch: 5[33600/40000 sentences]            Training Loss: 0.677666\n",
            "Training Epoch: 5[35200/40000 sentences]            Training Loss: 0.682398\n",
            "Training Epoch: 5[36800/40000 sentences]            Training Loss: 0.671755\n",
            "Training Epoch: 5[38400/40000 sentences]            Training Loss: 0.695495\n",
            "After Epoch: 5            Training Loss: 0.693693            Training Accuracy 8.046400            Validation Loss: 0.701497            Validation Accuracy 7.763578\n",
            "Training Epoch: 6[0/40000 sentences]            Training Loss: 0.675394\n",
            "Training Epoch: 6[1600/40000 sentences]            Training Loss: 0.676127\n",
            "Training Epoch: 6[3200/40000 sentences]            Training Loss: 0.703869\n",
            "Training Epoch: 6[4800/40000 sentences]            Training Loss: 0.703820\n",
            "Training Epoch: 6[6400/40000 sentences]            Training Loss: 0.714548\n",
            "Training Epoch: 6[8000/40000 sentences]            Training Loss: 0.698374\n",
            "Training Epoch: 6[9600/40000 sentences]            Training Loss: 0.689660\n",
            "Training Epoch: 6[11200/40000 sentences]            Training Loss: 0.682459\n",
            "Training Epoch: 6[12800/40000 sentences]            Training Loss: 0.688102\n",
            "Training Epoch: 6[14400/40000 sentences]            Training Loss: 0.692591\n",
            "Training Epoch: 6[16000/40000 sentences]            Training Loss: 0.686430\n",
            "Training Epoch: 6[17600/40000 sentences]            Training Loss: 0.683092\n",
            "Training Epoch: 6[19200/40000 sentences]            Training Loss: 0.707106\n",
            "Training Epoch: 6[20800/40000 sentences]            Training Loss: 0.686344\n",
            "Training Epoch: 6[22400/40000 sentences]            Training Loss: 0.688352\n",
            "Training Epoch: 6[24000/40000 sentences]            Training Loss: 0.701047\n",
            "Training Epoch: 6[25600/40000 sentences]            Training Loss: 0.692281\n",
            "Training Epoch: 6[27200/40000 sentences]            Training Loss: 0.694295\n",
            "Training Epoch: 6[28800/40000 sentences]            Training Loss: 0.698753\n",
            "Training Epoch: 6[30400/40000 sentences]            Training Loss: 0.693346\n",
            "Training Epoch: 6[32000/40000 sentences]            Training Loss: 0.701902\n",
            "Training Epoch: 6[33600/40000 sentences]            Training Loss: 0.698786\n",
            "Training Epoch: 6[35200/40000 sentences]            Training Loss: 0.691116\n",
            "Training Epoch: 6[36800/40000 sentences]            Training Loss: 0.671111\n",
            "Training Epoch: 6[38400/40000 sentences]            Training Loss: 0.728491\n",
            "After Epoch: 6            Training Loss: 0.693682            Training Accuracy 8.004000            Validation Loss: 0.695863            Validation Accuracy 7.827476\n",
            "Training Epoch: 7[0/40000 sentences]            Training Loss: 0.688848\n",
            "Training Epoch: 7[1600/40000 sentences]            Training Loss: 0.676684\n",
            "Training Epoch: 7[3200/40000 sentences]            Training Loss: 0.699847\n",
            "Training Epoch: 7[4800/40000 sentences]            Training Loss: 0.707967\n",
            "Training Epoch: 7[6400/40000 sentences]            Training Loss: 0.717590\n",
            "Training Epoch: 7[8000/40000 sentences]            Training Loss: 0.701440\n",
            "Training Epoch: 7[9600/40000 sentences]            Training Loss: 0.691494\n",
            "Training Epoch: 7[11200/40000 sentences]            Training Loss: 0.671911\n",
            "Training Epoch: 7[12800/40000 sentences]            Training Loss: 0.685272\n",
            "Training Epoch: 7[14400/40000 sentences]            Training Loss: 0.688954\n",
            "Training Epoch: 7[16000/40000 sentences]            Training Loss: 0.693680\n",
            "Training Epoch: 7[17600/40000 sentences]            Training Loss: 0.686994\n",
            "Training Epoch: 7[19200/40000 sentences]            Training Loss: 0.696549\n",
            "Training Epoch: 7[20800/40000 sentences]            Training Loss: 0.696093\n",
            "Training Epoch: 7[22400/40000 sentences]            Training Loss: 0.677543\n",
            "Training Epoch: 7[24000/40000 sentences]            Training Loss: 0.697314\n",
            "Training Epoch: 7[25600/40000 sentences]            Training Loss: 0.705694\n",
            "Training Epoch: 7[27200/40000 sentences]            Training Loss: 0.695165\n",
            "Training Epoch: 7[28800/40000 sentences]            Training Loss: 0.692404\n",
            "Training Epoch: 7[30400/40000 sentences]            Training Loss: 0.689577\n",
            "Training Epoch: 7[32000/40000 sentences]            Training Loss: 0.677717\n",
            "Training Epoch: 7[33600/40000 sentences]            Training Loss: 0.698036\n",
            "Training Epoch: 7[35200/40000 sentences]            Training Loss: 0.700526\n",
            "Training Epoch: 7[36800/40000 sentences]            Training Loss: 0.658045\n",
            "Training Epoch: 7[38400/40000 sentences]            Training Loss: 0.693640\n",
            "After Epoch: 7            Training Loss: 0.693133            Training Accuracy 8.122800            Validation Loss: 0.696200            Validation Accuracy 7.805112\n",
            "Training Epoch: 8[0/40000 sentences]            Training Loss: 0.677409\n",
            "Training Epoch: 8[1600/40000 sentences]            Training Loss: 0.673935\n",
            "Training Epoch: 8[3200/40000 sentences]            Training Loss: 0.706844\n",
            "Training Epoch: 8[4800/40000 sentences]            Training Loss: 0.696027\n",
            "Training Epoch: 8[6400/40000 sentences]            Training Loss: 0.702494\n",
            "Training Epoch: 8[8000/40000 sentences]            Training Loss: 0.698857\n",
            "Training Epoch: 8[9600/40000 sentences]            Training Loss: 0.692750\n",
            "Training Epoch: 8[11200/40000 sentences]            Training Loss: 0.675459\n",
            "Training Epoch: 8[12800/40000 sentences]            Training Loss: 0.686947\n",
            "Training Epoch: 8[14400/40000 sentences]            Training Loss: 0.691552\n",
            "Training Epoch: 8[16000/40000 sentences]            Training Loss: 0.694757\n",
            "Training Epoch: 8[17600/40000 sentences]            Training Loss: 0.700256\n",
            "Training Epoch: 8[19200/40000 sentences]            Training Loss: 0.706620\n",
            "Training Epoch: 8[20800/40000 sentences]            Training Loss: 0.695444\n",
            "Training Epoch: 8[22400/40000 sentences]            Training Loss: 0.684110\n",
            "Training Epoch: 8[24000/40000 sentences]            Training Loss: 0.699127\n",
            "Training Epoch: 8[25600/40000 sentences]            Training Loss: 0.695136\n",
            "Training Epoch: 8[27200/40000 sentences]            Training Loss: 0.696258\n",
            "Training Epoch: 8[28800/40000 sentences]            Training Loss: 0.704336\n",
            "Training Epoch: 8[30400/40000 sentences]            Training Loss: 0.682096\n",
            "Training Epoch: 8[32000/40000 sentences]            Training Loss: 0.682727\n",
            "Training Epoch: 8[33600/40000 sentences]            Training Loss: 0.704528\n",
            "Training Epoch: 8[35200/40000 sentences]            Training Loss: 0.688282\n",
            "Training Epoch: 8[36800/40000 sentences]            Training Loss: 0.689555\n",
            "Training Epoch: 8[38400/40000 sentences]            Training Loss: 0.694493\n",
            "After Epoch: 8            Training Loss: 0.692852            Training Accuracy 8.156400            Validation Loss: 0.699991            Validation Accuracy 7.766773\n",
            "Training Epoch: 9[0/40000 sentences]            Training Loss: 0.670915\n",
            "Training Epoch: 9[1600/40000 sentences]            Training Loss: 0.648913\n",
            "Training Epoch: 9[3200/40000 sentences]            Training Loss: 0.706006\n",
            "Training Epoch: 9[4800/40000 sentences]            Training Loss: 0.694474\n",
            "Training Epoch: 9[6400/40000 sentences]            Training Loss: 0.714522\n",
            "Training Epoch: 9[8000/40000 sentences]            Training Loss: 0.687602\n",
            "Training Epoch: 9[9600/40000 sentences]            Training Loss: 0.703385\n",
            "Training Epoch: 9[11200/40000 sentences]            Training Loss: 0.671653\n",
            "Training Epoch: 9[12800/40000 sentences]            Training Loss: 0.688287\n",
            "Training Epoch: 9[14400/40000 sentences]            Training Loss: 0.682923\n",
            "Training Epoch: 9[16000/40000 sentences]            Training Loss: 0.695117\n",
            "Training Epoch: 9[17600/40000 sentences]            Training Loss: 0.676314\n",
            "Training Epoch: 9[19200/40000 sentences]            Training Loss: 0.706066\n",
            "Training Epoch: 9[20800/40000 sentences]            Training Loss: 0.660401\n",
            "Training Epoch: 9[22400/40000 sentences]            Training Loss: 0.703402\n",
            "Training Epoch: 9[24000/40000 sentences]            Training Loss: 0.691039\n",
            "Training Epoch: 9[25600/40000 sentences]            Training Loss: 0.701677\n",
            "Training Epoch: 9[27200/40000 sentences]            Training Loss: 0.679830\n",
            "Training Epoch: 9[28800/40000 sentences]            Training Loss: 0.701173\n",
            "Training Epoch: 9[30400/40000 sentences]            Training Loss: 0.692322\n",
            "Training Epoch: 9[32000/40000 sentences]            Training Loss: 0.655618\n",
            "Training Epoch: 9[33600/40000 sentences]            Training Loss: 0.687885\n",
            "Training Epoch: 9[35200/40000 sentences]            Training Loss: 0.679562\n",
            "Training Epoch: 9[36800/40000 sentences]            Training Loss: 0.676402\n",
            "Training Epoch: 9[38400/40000 sentences]            Training Loss: 0.712381\n",
            "After Epoch: 9            Training Loss: 0.691777            Training Accuracy 8.233600            Validation Loss: 0.699616            Validation Accuracy 7.872204\n",
            "Training Epoch: 10[0/40000 sentences]            Training Loss: 0.678587\n",
            "Training Epoch: 10[1600/40000 sentences]            Training Loss: 0.660819\n",
            "Training Epoch: 10[3200/40000 sentences]            Training Loss: 0.694224\n",
            "Training Epoch: 10[4800/40000 sentences]            Training Loss: 0.689870\n",
            "Training Epoch: 10[6400/40000 sentences]            Training Loss: 0.760598\n",
            "Training Epoch: 10[8000/40000 sentences]            Training Loss: 0.701716\n",
            "Training Epoch: 10[9600/40000 sentences]            Training Loss: 0.681307\n",
            "Training Epoch: 10[11200/40000 sentences]            Training Loss: 0.703305\n",
            "Training Epoch: 10[12800/40000 sentences]            Training Loss: 0.688521\n",
            "Training Epoch: 10[14400/40000 sentences]            Training Loss: 0.688410\n",
            "Training Epoch: 10[16000/40000 sentences]            Training Loss: 0.700342\n",
            "Training Epoch: 10[17600/40000 sentences]            Training Loss: 0.680310\n",
            "Training Epoch: 10[19200/40000 sentences]            Training Loss: 0.719251\n",
            "Training Epoch: 10[20800/40000 sentences]            Training Loss: 0.677416\n",
            "Training Epoch: 10[22400/40000 sentences]            Training Loss: 0.689021\n",
            "Training Epoch: 10[24000/40000 sentences]            Training Loss: 0.725890\n",
            "Training Epoch: 10[25600/40000 sentences]            Training Loss: 0.690426\n",
            "Training Epoch: 10[27200/40000 sentences]            Training Loss: 0.680740\n",
            "Training Epoch: 10[28800/40000 sentences]            Training Loss: 0.713001\n",
            "Training Epoch: 10[30400/40000 sentences]            Training Loss: 0.707686\n",
            "Training Epoch: 10[32000/40000 sentences]            Training Loss: 0.698205\n",
            "Training Epoch: 10[33600/40000 sentences]            Training Loss: 0.686804\n",
            "Training Epoch: 10[35200/40000 sentences]            Training Loss: 0.680354\n",
            "Training Epoch: 10[36800/40000 sentences]            Training Loss: 0.669887\n",
            "Training Epoch: 10[38400/40000 sentences]            Training Loss: 0.695301\n",
            "After Epoch: 10            Training Loss: 0.690327            Training Accuracy 8.233200            Validation Loss: 0.704801            Validation Accuracy 7.798722\n",
            "Training Epoch: 11[0/40000 sentences]            Training Loss: 0.719727\n",
            "Training Epoch: 11[1600/40000 sentences]            Training Loss: 0.618641\n",
            "Training Epoch: 11[3200/40000 sentences]            Training Loss: 0.710204\n",
            "Training Epoch: 11[4800/40000 sentences]            Training Loss: 0.723249\n",
            "Training Epoch: 11[6400/40000 sentences]            Training Loss: 0.726749\n",
            "Training Epoch: 11[8000/40000 sentences]            Training Loss: 0.686960\n",
            "Training Epoch: 11[9600/40000 sentences]            Training Loss: 0.693878\n",
            "Training Epoch: 11[11200/40000 sentences]            Training Loss: 0.690914\n",
            "Training Epoch: 11[12800/40000 sentences]            Training Loss: 0.682540\n",
            "Training Epoch: 11[14400/40000 sentences]            Training Loss: 0.702153\n",
            "Training Epoch: 11[16000/40000 sentences]            Training Loss: 0.667863\n",
            "Training Epoch: 11[17600/40000 sentences]            Training Loss: 0.688006\n",
            "Training Epoch: 11[19200/40000 sentences]            Training Loss: 0.727354\n",
            "Training Epoch: 11[20800/40000 sentences]            Training Loss: 0.682969\n",
            "Training Epoch: 11[22400/40000 sentences]            Training Loss: 0.691662\n",
            "Training Epoch: 11[24000/40000 sentences]            Training Loss: 0.772113\n",
            "Training Epoch: 11[25600/40000 sentences]            Training Loss: 0.668248\n",
            "Training Epoch: 11[27200/40000 sentences]            Training Loss: 0.668208\n",
            "Training Epoch: 11[28800/40000 sentences]            Training Loss: 0.711965\n",
            "Training Epoch: 11[30400/40000 sentences]            Training Loss: 0.697861\n",
            "Training Epoch: 11[32000/40000 sentences]            Training Loss: 0.690258\n",
            "Training Epoch: 11[33600/40000 sentences]            Training Loss: 0.752319\n",
            "Training Epoch: 11[35200/40000 sentences]            Training Loss: 0.692243\n",
            "Training Epoch: 11[36800/40000 sentences]            Training Loss: 0.685274\n",
            "Training Epoch: 11[38400/40000 sentences]            Training Loss: 0.713362\n",
            "After Epoch: 11            Training Loss: 0.689112            Training Accuracy 8.274800            Validation Loss: 0.706880            Validation Accuracy 7.811502\n",
            "Training Epoch: 12[0/40000 sentences]            Training Loss: 0.653824\n",
            "Training Epoch: 12[1600/40000 sentences]            Training Loss: 0.647059\n",
            "Training Epoch: 12[3200/40000 sentences]            Training Loss: 0.726406\n",
            "Training Epoch: 12[4800/40000 sentences]            Training Loss: 0.711460\n",
            "Training Epoch: 12[6400/40000 sentences]            Training Loss: 0.709162\n",
            "Training Epoch: 12[8000/40000 sentences]            Training Loss: 0.699981\n",
            "Training Epoch: 12[9600/40000 sentences]            Training Loss: 0.735747\n",
            "Training Epoch: 12[11200/40000 sentences]            Training Loss: 0.698297\n",
            "Training Epoch: 12[12800/40000 sentences]            Training Loss: 0.674331\n",
            "Training Epoch: 12[14400/40000 sentences]            Training Loss: 0.678035\n",
            "Training Epoch: 12[16000/40000 sentences]            Training Loss: 0.692927\n",
            "Training Epoch: 12[17600/40000 sentences]            Training Loss: 0.690893\n",
            "Training Epoch: 12[19200/40000 sentences]            Training Loss: 0.725391\n",
            "Training Epoch: 12[20800/40000 sentences]            Training Loss: 0.689082\n",
            "Training Epoch: 12[22400/40000 sentences]            Training Loss: 0.671457\n",
            "Training Epoch: 12[24000/40000 sentences]            Training Loss: 0.703972\n",
            "Training Epoch: 12[25600/40000 sentences]            Training Loss: 0.679817\n",
            "Training Epoch: 12[27200/40000 sentences]            Training Loss: 0.676459\n",
            "Training Epoch: 12[28800/40000 sentences]            Training Loss: 0.694401\n",
            "Training Epoch: 12[30400/40000 sentences]            Training Loss: 0.678542\n",
            "Training Epoch: 12[32000/40000 sentences]            Training Loss: 0.682228\n",
            "Training Epoch: 12[33600/40000 sentences]            Training Loss: 0.727706\n",
            "Training Epoch: 12[35200/40000 sentences]            Training Loss: 0.754847\n",
            "Training Epoch: 12[36800/40000 sentences]            Training Loss: 0.699227\n",
            "Training Epoch: 12[38400/40000 sentences]            Training Loss: 0.700620\n",
            "After Epoch: 12            Training Loss: 0.688415            Training Accuracy 8.319200            Validation Loss: 0.702899            Validation Accuracy 7.824281\n",
            "Training Epoch: 13[0/40000 sentences]            Training Loss: 0.679833\n",
            "Training Epoch: 13[1600/40000 sentences]            Training Loss: 0.633072\n",
            "Training Epoch: 13[3200/40000 sentences]            Training Loss: 0.681600\n",
            "Training Epoch: 13[4800/40000 sentences]            Training Loss: 0.696176\n",
            "Training Epoch: 13[6400/40000 sentences]            Training Loss: 0.650799\n",
            "Training Epoch: 13[8000/40000 sentences]            Training Loss: 0.656273\n",
            "Training Epoch: 13[9600/40000 sentences]            Training Loss: 0.695957\n",
            "Training Epoch: 13[11200/40000 sentences]            Training Loss: 0.670402\n",
            "Training Epoch: 13[12800/40000 sentences]            Training Loss: 0.668475\n",
            "Training Epoch: 13[14400/40000 sentences]            Training Loss: 0.637427\n",
            "Training Epoch: 13[16000/40000 sentences]            Training Loss: 0.686479\n",
            "Training Epoch: 13[17600/40000 sentences]            Training Loss: 0.679391\n",
            "Training Epoch: 13[19200/40000 sentences]            Training Loss: 0.714311\n",
            "Training Epoch: 13[20800/40000 sentences]            Training Loss: 0.680797\n",
            "Training Epoch: 13[22400/40000 sentences]            Training Loss: 0.682187\n",
            "Training Epoch: 13[24000/40000 sentences]            Training Loss: 0.741279\n",
            "Training Epoch: 13[25600/40000 sentences]            Training Loss: 0.711692\n",
            "Training Epoch: 13[27200/40000 sentences]            Training Loss: 0.678885\n",
            "Training Epoch: 13[28800/40000 sentences]            Training Loss: 0.705102\n",
            "Training Epoch: 13[30400/40000 sentences]            Training Loss: 0.650922\n",
            "Training Epoch: 13[32000/40000 sentences]            Training Loss: 0.641648\n",
            "Training Epoch: 13[33600/40000 sentences]            Training Loss: 0.664179\n",
            "Training Epoch: 13[35200/40000 sentences]            Training Loss: 0.676715\n",
            "Training Epoch: 13[36800/40000 sentences]            Training Loss: 0.692878\n",
            "Training Epoch: 13[38400/40000 sentences]            Training Loss: 0.698886\n",
            "After Epoch: 13            Training Loss: 0.685501            Training Accuracy 8.386400            Validation Loss: 0.703481            Validation Accuracy 7.808307\n",
            "Training Epoch: 14[0/40000 sentences]            Training Loss: 0.677270\n",
            "Training Epoch: 14[1600/40000 sentences]            Training Loss: 0.626913\n",
            "Training Epoch: 14[3200/40000 sentences]            Training Loss: 0.712640\n",
            "Training Epoch: 14[4800/40000 sentences]            Training Loss: 0.714605\n",
            "Training Epoch: 14[6400/40000 sentences]            Training Loss: 0.672572\n",
            "Training Epoch: 14[8000/40000 sentences]            Training Loss: 0.668194\n",
            "Training Epoch: 14[9600/40000 sentences]            Training Loss: 0.684943\n",
            "Training Epoch: 14[11200/40000 sentences]            Training Loss: 0.693344\n",
            "Training Epoch: 14[12800/40000 sentences]            Training Loss: 0.696619\n",
            "Training Epoch: 14[14400/40000 sentences]            Training Loss: 0.659924\n",
            "Training Epoch: 14[16000/40000 sentences]            Training Loss: 0.680190\n",
            "Training Epoch: 14[17600/40000 sentences]            Training Loss: 0.679923\n",
            "Training Epoch: 14[19200/40000 sentences]            Training Loss: 0.700117\n",
            "Training Epoch: 14[20800/40000 sentences]            Training Loss: 0.654630\n",
            "Training Epoch: 14[22400/40000 sentences]            Training Loss: 0.701944\n",
            "Training Epoch: 14[24000/40000 sentences]            Training Loss: 0.662827\n",
            "Training Epoch: 14[25600/40000 sentences]            Training Loss: 0.668022\n",
            "Training Epoch: 14[27200/40000 sentences]            Training Loss: 0.648335\n",
            "Training Epoch: 14[28800/40000 sentences]            Training Loss: 0.709807\n",
            "Training Epoch: 14[30400/40000 sentences]            Training Loss: 0.677642\n",
            "Training Epoch: 14[32000/40000 sentences]            Training Loss: 0.665477\n",
            "Training Epoch: 14[33600/40000 sentences]            Training Loss: 0.758198\n",
            "Training Epoch: 14[35200/40000 sentences]            Training Loss: 0.699396\n",
            "Training Epoch: 14[36800/40000 sentences]            Training Loss: 0.700439\n",
            "Training Epoch: 14[38400/40000 sentences]            Training Loss: 0.742806\n",
            "After Epoch: 14            Training Loss: 0.684252            Training Accuracy 8.476400            Validation Loss: 0.702926            Validation Accuracy 7.776358\n",
            "Training Epoch: 15[0/40000 sentences]            Training Loss: 0.678493\n",
            "Training Epoch: 15[1600/40000 sentences]            Training Loss: 0.653149\n",
            "Training Epoch: 15[3200/40000 sentences]            Training Loss: 0.725709\n",
            "Training Epoch: 15[4800/40000 sentences]            Training Loss: 0.703321\n",
            "Training Epoch: 15[6400/40000 sentences]            Training Loss: 0.655579\n",
            "Training Epoch: 15[8000/40000 sentences]            Training Loss: 0.699019\n",
            "Training Epoch: 15[9600/40000 sentences]            Training Loss: 0.713036\n",
            "Training Epoch: 15[11200/40000 sentences]            Training Loss: 0.695215\n",
            "Training Epoch: 15[12800/40000 sentences]            Training Loss: 0.672816\n",
            "Training Epoch: 15[14400/40000 sentences]            Training Loss: 0.599225\n",
            "Training Epoch: 15[16000/40000 sentences]            Training Loss: 0.681451\n",
            "Training Epoch: 15[17600/40000 sentences]            Training Loss: 0.653498\n",
            "Training Epoch: 15[19200/40000 sentences]            Training Loss: 0.697307\n",
            "Training Epoch: 15[20800/40000 sentences]            Training Loss: 0.719007\n",
            "Training Epoch: 15[22400/40000 sentences]            Training Loss: 0.674352\n",
            "Training Epoch: 15[24000/40000 sentences]            Training Loss: 0.709296\n",
            "Training Epoch: 15[25600/40000 sentences]            Training Loss: 0.658560\n",
            "Training Epoch: 15[27200/40000 sentences]            Training Loss: 0.686954\n",
            "Training Epoch: 15[28800/40000 sentences]            Training Loss: 0.721129\n",
            "Training Epoch: 15[30400/40000 sentences]            Training Loss: 0.702483\n",
            "Training Epoch: 15[32000/40000 sentences]            Training Loss: 0.662409\n",
            "Training Epoch: 15[33600/40000 sentences]            Training Loss: 0.678315\n",
            "Training Epoch: 15[35200/40000 sentences]            Training Loss: 0.688693\n",
            "Training Epoch: 15[36800/40000 sentences]            Training Loss: 0.678486\n",
            "Training Epoch: 15[38400/40000 sentences]            Training Loss: 0.729559\n",
            "After Epoch: 15            Training Loss: 0.682449            Training Accuracy 8.420800            Validation Loss: 0.707641            Validation Accuracy 7.808307\n",
            "Training Epoch: 16[0/40000 sentences]            Training Loss: 0.654104\n",
            "Training Epoch: 16[1600/40000 sentences]            Training Loss: 0.691797\n",
            "Training Epoch: 16[3200/40000 sentences]            Training Loss: 0.701273\n",
            "Training Epoch: 16[4800/40000 sentences]            Training Loss: 0.739680\n",
            "Training Epoch: 16[6400/40000 sentences]            Training Loss: 0.677476\n",
            "Training Epoch: 16[8000/40000 sentences]            Training Loss: 0.700500\n",
            "Training Epoch: 16[9600/40000 sentences]            Training Loss: 0.720149\n",
            "Training Epoch: 16[11200/40000 sentences]            Training Loss: 0.704003\n",
            "Training Epoch: 16[12800/40000 sentences]            Training Loss: 0.671370\n",
            "Training Epoch: 16[14400/40000 sentences]            Training Loss: 0.632013\n",
            "Training Epoch: 16[16000/40000 sentences]            Training Loss: 0.677644\n",
            "Training Epoch: 16[17600/40000 sentences]            Training Loss: 0.684077\n",
            "Training Epoch: 16[19200/40000 sentences]            Training Loss: 0.741501\n",
            "Training Epoch: 16[20800/40000 sentences]            Training Loss: 0.636677\n",
            "Training Epoch: 16[22400/40000 sentences]            Training Loss: 0.709736\n",
            "Training Epoch: 16[24000/40000 sentences]            Training Loss: 0.636497\n",
            "Training Epoch: 16[25600/40000 sentences]            Training Loss: 0.676160\n",
            "Training Epoch: 16[27200/40000 sentences]            Training Loss: 0.672397\n",
            "Training Epoch: 16[28800/40000 sentences]            Training Loss: 0.706681\n",
            "Training Epoch: 16[30400/40000 sentences]            Training Loss: 0.678132\n",
            "Training Epoch: 16[32000/40000 sentences]            Training Loss: 0.678723\n",
            "Training Epoch: 16[33600/40000 sentences]            Training Loss: 0.735378\n",
            "Training Epoch: 16[35200/40000 sentences]            Training Loss: 0.694916\n",
            "Training Epoch: 16[36800/40000 sentences]            Training Loss: 0.742597\n",
            "Training Epoch: 16[38400/40000 sentences]            Training Loss: 0.701251\n",
            "After Epoch: 16            Training Loss: 0.679763            Training Accuracy 8.525200            Validation Loss: 0.708416            Validation Accuracy 7.776358\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "G-EEiviJZ-do",
        "outputId": "c6f00283-4233-48a6-edfb-6941cdd654eb"
      },
      "source": [
        "! ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "first_run.pkl  glove.6B.zip  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "r0PxlNkKOJIS",
        "outputId": "47b1eb4d-3a95-426d-8730-f61c14b01cfe"
      },
      "source": [
        "fig,axes = plt.subplots(1,4,figsize=(25,6))\n",
        "axes[0].plot(list(range(0,len(trainLosses),1)),trainLosses,label=\"Training loss\")\n",
        "axes[0].legend()\n",
        "axes[1].plot(validationLoss,label=\"Validation loss\")\n",
        "axes[1].legend()\n",
        "axes[2].plot(trainAccuracy,label=\"Training accuracy\")\n",
        "axes[2].legend()\n",
        "axes[3].plot(validationAccuracy,label=\"Validation accuracy\")\n",
        "axes[3].legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1800x432 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "do4X9Z0tbg3f",
        "outputId": "881029c3-d657-49ce-a379-3fc10c86d05b"
      },
      "source": [
        "print(\"Time taken in minutes\",(end-start)/60)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time taken in minutes 48.648439383506776\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rOjmNELM9av"
      },
      "source": [
        "# **Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Hk3YIUgfLTo8",
        "outputId": "e4d13be2-9b29-4891-baad-36c9651fb3ae"
      },
      "source": [
        "model.eval()\n",
        "\n",
        "softmax = torch.nn.Softmax()\n",
        "true = []\n",
        "pred = []\n",
        "with torch.no_grad():\n",
        "    test_loss = 0\n",
        "    test_accuracy = 0\n",
        "    for _, (test_batch, test_labels ) in enumerate(testLoader):                    \n",
        "        # test_batch = test_batch.reshape(sequence_length,batch_size ,input_size).to(device)\n",
        "    \n",
        "        test_batch = test_batch.reshape(sequence_length,-1 ,input_size).to(device)\n",
        "        test_labels = test_labels.to(device)\n",
        "        test_outputs = model(test_batch).to(device)\n",
        "\n",
        "        \n",
        "        probabilities = softmax(test_outputs) \n",
        "        # print(probabilities)\n",
        "        test_loss+= (criterion(test_outputs, test_labels.long()).item())\n",
        "        test_predictions, test_predicted_class = torch.max(probabilities, 1)\n",
        "       \n",
        "        test_accuracy+=(torch.sum(test_predicted_class==test_labels).item())\n",
        "        \n",
        "        true.extend(test_labels)\n",
        "        pred.extend(test_predictions)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Vr4v8WM8x0hf",
        "outputId": "46a9dbe0-08c5-4bd4-c3da-0d36728cae6f"
      },
      "source": [
        "print(\"Test loss is\",test_loss/len(testLoader.dataset))\n",
        "print(\" Accuracy is\",test_accuracy/len(testLoader.dataset)*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss is 0.04413525539636612\n",
            " Accuracy is 50.339999999999996\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTNCMcHEBS1b"
      },
      "source": [
        "roc = roc_curve(true,pred)\n",
        "true_positive_rate = np.array(roc)[:,1]\n",
        "false_positve_rate = np.array(roc)[:,2]\n",
        "\n",
        "print(auc(true_positive_rate,false_positve_rate))\n",
        "precision = np.array(roc)[:,3]\n",
        "\n",
        "fig,axes = plt.subplots(1,2)\n",
        "\n",
        "axes[0].scatter(true_positive_rate,false_positve_rate)\n",
        "axes[1].scatter(true_positive_rate,precision)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jmI-Mp1VCquC"
      },
      "source": [
        "class BLSTM_ATTENTION(nn.Module):\n",
        "    def __init__(self,input_size,sequence_length,hidden_size,num_layers,num_classes,batch_size,batch_first=False):\n",
        "        super(BLSTM_ATTENTION,self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size=hidden_size     #size of the hidden layer\n",
        "        self.num_layers=num_layers       #if the lstm is stacked\n",
        "        self.batch_first=batch_first \n",
        "        self.batch_size = batch_size\n",
        "        self.sequence_length = sequence_length\n",
        "\n",
        "        #input size will be the size of the inputs x1,...xn\n",
        "        #hidden state has hidden_size\n",
        "        self.bidirLSTM = nn.LSTM(input_size,hidden_size,num_layers,batch_first,dropout = 0.5,bidirectional=True)\n",
        "        \n",
        "        self.attention = nn.Sequential(\n",
        "                                nn.Linear(self.hidden_size,32),\n",
        "                                nn.ReLU(),\n",
        "                                nn.Linear(32,1)\n",
        "                                )\n",
        "             \n",
        "        self.fullyconnected = nn.Linear(hidden_size,num_classes)\n",
        "    def forward(self,x):\n",
        "        #initialze the weights to 0, for every element in the batch\n",
        "        #num_layer,batch_size, hidden_size\n",
        "        \n",
        "        #x.size(1) is the batch size\n",
        "        h_0 = torch.zeros(self.num_layers*2,x.size(1),self.hidden_size).to(device)\n",
        "        c_0 = torch.zeros(self.num_layers*2,x.size(1),self.hidden_size).to(device)\n",
        "        # seqlen,batch, hidden_size*2\n",
        "        out, (h_n,c_n) = self.bidirLSTM(x,(h_0,c_0))\n",
        "        #seq,batch,  hidden\n",
        "        out = out[:, :, :self.hidden_size] + out[:, :, self.hidden_size:]\n",
        "        \n",
        "#         print(\"after joining forward and backward\",out.shape)\n",
        "        \n",
        "        batch = out.size(1)\n",
        "\n",
        "        #for attention make the input to have the output size as the hidden_size\n",
        "        #the attention will return value for the entire batch of sequence\n",
        "        attention_out = self.attention(out.view(-1, self.hidden_size)) # (seq, batch, hidden) -> (seq* batch, 1)\n",
        "        #take softmax of the attention\n",
        "        attention_out = nn.functional.softmax(attention_out.view(batch, -1), dim=1).unsqueeze(2) # (seq* batch, 1) -> (seq, batch, 1)\n",
        "\n",
        "        #making the dimension to be batch sequence 1, multiply the out and the attention layer softmax output probabilities\n",
        "        matrix_mul = (out.permute(1,0,2)* attention_out).sum(dim=1)    \n",
        "\n",
        "        #pass throught the fully connected layer\n",
        "        out = self.fullyconnected(matrix_mul) #b*2\n",
        "        \n",
        "        return out      \n",
        "\n",
        "\n",
        "# embed_size = 50\n",
        "sequence_length = max_length #500\n",
        "input_size = embed_size #50\n",
        "hidden_size = 128\n",
        "num_layers = 2\n",
        "num_classes = 2\n",
        "num_epochs = 2\n",
        "batch_size = 32\n",
        "try:\n",
        "    attention_model = BLSTM_ATTENTION(input_size,sequence_length, hidden_size, num_layers, num_classes,batch_size).to(device)\n",
        "except:\n",
        "    attention_model = BLSTM_ATTENTION(input_size,sequence_length, hidden_size, num_layers, num_classes,batch_size)\n",
        "\n",
        "    \n",
        "learning_rate = 0.003\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(attention_model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toLaQ3L0ONZf"
      },
      "source": [
        "# **Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TfIA8ZhDFRyQ"
      },
      "source": [
        "epoch,nEpochs = 0,15\n",
        "log_interval = 100  #step size\n",
        "\n",
        "dataset_size = len(trainLoader.dataset) #number of reviews in training dataset\n",
        "valdata_size = len(valLoader.dataset) #number of reviews in validation dataset\n",
        "best_accuracy = math.inf\n",
        "trainLosses,trainAccuracy,validationAccuracy = [],[],[]\n",
        "validationLoss =[]\n",
        "clip =5\n",
        "# fig,axes = plt.subplots(1,4,figsize=(25,6))\n",
        "start = time.time()\n",
        "\n",
        "while epoch <= nEpochs:# and not stop_training:\n",
        "\n",
        "    attention_model.train()\n",
        "    running_corrects = 0\n",
        "    running_loss = 0\n",
        "    batch = 0\n",
        "    for batch_num, (seq, labels) in enumerate(trainLoader):\n",
        "        # seq = seq.reshape(sequence_length,batch_size ,input_size).to(device)\n",
        "        seq = seq.reshape(sequence_length,-1 ,input_size).to(device)  #the batch size might not be same as batch_size for the last batch\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        outputs = attention_model(seq).to(device)\n",
        "        _,predictions =  torch.max(outputs, 1) #max of the final layer \n",
        "        running_corrects += (torch.sum(predictions==labels).item()) #number of right predicitions         \n",
        "        \n",
        "        #backpropagate\n",
        "        with torch.set_grad_enabled(True):\n",
        "            loss = criterion(outputs, labels.long())\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(attention_model.parameters(), clip)\n",
        "            optimizer.step()\n",
        "\n",
        "        loss_value = loss.detach().item()\n",
        "        running_loss += loss_value\n",
        "        # batch += len(trainLoader)\n",
        "        if batch_num % log_interval == 0:  #at step size, output batch loss        \n",
        "            print('Training Epoch: {0}[{1}/{2} sentences]\\\n",
        "            Training Loss: {3:.6f}'.format(epoch+1, batch_num * batch_size,dataset_size,loss_value))   \n",
        "    trainAccuracy.append(running_corrects/len(trainLoader))\n",
        "    trainLosses.append(running_loss/len(trainLoader))\n",
        "\n",
        "\n",
        "    #validation\n",
        "    attention_model.eval()\n",
        "    with torch.set_grad_enabled(False):  #gradient not backpack propagated\n",
        "        val_losses = 0\n",
        "        val_accuracy = 0\n",
        "        for _, (val_batch, val_labels ) in enumerate(valLoader):                    \n",
        "            # val_batch = val_batch.reshape(sequence_length,batch_size ,input_size).to(device)\n",
        "            val_batch = val_batch.reshape(sequence_length,-1 ,input_size).to(device)\n",
        "            val_labels = val_labels.to(device)\n",
        "            val_outputs = attention_model(val_batch).to(device)\n",
        "            #find the average loss and the total loss\n",
        "            val_losses+=(criterion(val_outputs, val_labels.long()).item())\n",
        "\n",
        "            _, val_predictions = torch.max(val_outputs, 1)\n",
        "            val_accuracy+=(torch.sum(val_predictions==val_labels).item() )\n",
        "\n",
        "        validationAccuracy.append(val_accuracy/len(valLoader)) \n",
        "        validationLoss.append(val_losses/len(valLoader))\n",
        "\n",
        "    print('After Epoch: {0}\\\n",
        "            Training Loss: {1:.6f}\\\n",
        "            Training Accuracy {2:.6f}\\\n",
        "            Validation Loss: {3:.6f}\\\n",
        "            Validation Accuracy {4:.6f}'.format(epoch+1,trainLosses[-1],trainAccuracy[-1],validationLoss[-1],validationAccuracy[-1])) \n",
        "        \n",
        "    \n",
        "    if validationAccuracy[-1] > best_accuracy:\n",
        "            best_Accuracy = validationAccuracy[-1]\n",
        "            best_model_weights = copy.deepcopy(attention_model.state_dict())            \n",
        "            torch.save(best_model_weights, path+filename+\".pt\") \n",
        "    with open(path+filename+\".pkl\",\"wb\") as f:\n",
        "        pickle.dump([trainLosses,trainAccuracy,validationAccuracy],f)\n",
        "                                 \n",
        "    # axes[0].plot(trainLosses,label=\"Training loss\")\n",
        "    # axes[1].plot(validationLoss,label=\"Validation loss\")\n",
        "    # axes[3].plot(validationAccuracy,label=\"Validation accuracy\")\n",
        "    # axes[2].plot(trainAccuracy,label=\"Training accuracy\")\n",
        "    \n",
        "    epoch = epoch + 1\n",
        "    \n",
        "end = time.time()\n",
        "# plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mXgf50xTFRyY"
      },
      "source": [
        "fig,axes = plt.subplots(1,4,figsize=(25,6))\n",
        "axes[0].plot(list(range(0,len(trainLosses),1)),trainLosses,label=\"Training loss\")\n",
        "axes[0].legend()\n",
        "axes[1].plot(validationLoss,label=\"Validation loss\")\n",
        "axes[1].legend()\n",
        "axes[2].plot(trainAccuracy,label=\"Training accuracy\")\n",
        "axes[2].legend()\n",
        "axes[3].plot(validationAccuracy,label=\"Validation accuracy\")\n",
        "axes[3].legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxm7WUQIORLO"
      },
      "source": [
        "# **Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KORfud52FwzH"
      },
      "source": [
        "attention_model.eval()\n",
        "\n",
        "softmax = torch.nn.Softmax()\n",
        "true = []\n",
        "pred = []\n",
        "with torch.no_grad():\n",
        "    test_loss = 0\n",
        "    test_accuracy = 0\n",
        "    for _, (test_batch, test_labels ) in enumerate(testLoader):                    \n",
        "        # test_batch = test_batch.reshape(sequence_length,batch_size ,input_size).to(device)\n",
        "    \n",
        "        test_batch = test_batch.reshape(sequence_length,-1 ,input_size).to(device)\n",
        "        test_labels = test_labels.to(device)\n",
        "        test_outputs = attention_model(test_batch).to(device)\n",
        "\n",
        "        \n",
        "        probabilities = softmax(test_outputs) \n",
        "        # print(probabilities)\n",
        "        test_loss+= (criterion(test_outputs, test_labels.long()).item())\n",
        "        test_predictions, test_predicted_class = torch.max(probabilities, 1)\n",
        "       \n",
        "        test_accuracy+=(torch.sum(test_predicted_class==test_labels).item())\n",
        "        \n",
        "        true.extend(test_labels)\n",
        "        pred.extend(test_predictions)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_iEZmwhGDfP"
      },
      "source": [
        "print(\"Test loss is\",test_loss/len(testLoader.dataset))\n",
        "print(\" Accuracy is\",test_accuracy/len(testLoader.dataset)*100)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}